## 常见存储

* DAS

	一个裸设备，可以理解为一个可以安装N多块磁盘的设备，然后通过数据线连接到服务器，这样服务器就可以识别这个“大磁盘”了。然后，在该服务器上分区、格式化、挂载该“大磁盘”。

* SAN

	也是一个支持安装N多块硬盘的设备，和DAS不同的是，它支持通过网线、光纤连接到一个网络里，然后同一个网络内的服务器可以通过网络连接到该设备，服务器会认为这个“大磁盘”是本地磁盘，然后进行分区、格式化、挂载等操作。

* NAS

	NAS其实是一台服务器，只不过这个服务器带着一块超级大的磁盘，然后该服务器通过网络共享的方式将这个“大磁盘”共享给其他服务器，其他服务器直接挂载就行了，不用分区、格式化，类似NFS。

* 分布式文件系统

	基于分布式系统理论，构建的网络集群存储系统。它可以将N多台服务器的磁盘资源组合在一起，构成一个”大磁盘“，支持高可用和扩容。当容量不够用时，只需要增加服务器，就可以扩容整个存储容量。

### 存储类型

* 块存储

	提供给用户的是一个类似磁盘的裸设备，在应用服务器上可以分区、格式化和挂载。DAS、SAN属于这一类。

* 对象存储

	用户不关心其实现细节，而只需关心读写的行为。它把存储的文件看作是一个对象，通过特有的接口去存储、读取、删除文件。阿里云OSS、腾讯云COS、七牛云SLA属于这一类。

* 文件存储

	NAS、NFS属于这一类，它直接给用户提供了文件系统，不用格式化，只需要挂载就可以用了。用户可以像使用本地文件系统一样去使用该类存储。
	
## 分布式文件系统

关于分布式系统参考文档：https://www.cnblogs.com/xybaby/p/7787034.html

### 常见的分布式文件系统

常见的分布式文件系统有，GFS、HDFS、Lustre 、Ceph 、GridFS 、mogileFS、TFS、FastDFS、Moosefs(MFS)等。各自适用于不同的领域。它们都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。

参考文档：https://blog.csdn.net/rickiyeat/article/details/53895987

## 分布式文件系统 -- ceph

Ceph是一套高性能，易扩展的，无单点的分布式文件存储系统，基于Sage A. Weil的论文开发，主要提供以下三个存储服务：

对象存储(Object Storage)，既可以通过使用Ceph的库，利用C, C++, Java, Python, PHP代码，也可以通过Restful网关以对象的形式访问或存储数据，兼容亚马逊的S3和OpenStack的Swift。

块存储(Block Storage)，作为块设备像硬盘一样直接挂载。

文件系统(File System) ，如同网络文件系统一样挂载，兼容POSIX接口。

参考 https://www.zhihu.com/question/21718731

### ceph核心组件

Ceph相关的概念或组件：RADOS, OSD, MON, MDS, LIBRADOS, RBD, RGW, Ceph FS。

参考：https://blog.frognew.com/2017/02/intro-ceph.html

### ceph的搭建

官方文档：http://docs.ceph.com/docs/master/

说明：以下操作步骤参考官方文档，使用ceph-deploy来完成部署。以下文档基于3台虚拟机（CentOS7）完成搭建：

主机名 | IP |角色
-------|---------|----
aminglinux01|192.168.222.128|部署节点、mon节点、osd节点
aminglinux02|192.168.222.129|mon节点、osd节点
aminglinux03|192.168.222.130|mon节点、osd节点

> 在做以下操作之前，需要先在所有机器上增加一块硬盘(/dev/sdb)

1）安装ceph-deploy（aminglinux01上执行）

```
#安装epel源
yum install -y epel-release 

#配置ceph源
cat << EOM > /etc/yum.repos.d/ceph.repo
[ceph-noarch]
name=Ceph noarch packages
baseurl=https://download.ceph.com/rpm-{ceph-stable-release}/el7/noarch
enabled=1
gpgcheck=1
type=rpm-md
gpgkey=https://download.ceph.com/keys/release.asc
EOM

#安装ceph-depoly
yum install ceph-deploy
```

2）配置时间同步（三个节点都执行）

```
# 安装ntpdate工具
yum install -y ntpdate

# 配置同步时间的任务计划
echo "*/5 * * * * ntpdate 1.cn.pool.ntp.org &>/dev/null" >>/var/spool/cron/root
```

3）配置hostname以及hosts（三台机器都需要）
```
# hostname
hostnamectl set-hostname aminglinux01 #另外两个机器分别为aminglinux02和aminglinux03

# hosts
vi /etc/hosts #加入如下
192.168.222.128 aminglinux01
192.168.222.129 aminglinux02
192.168.222.130 aminglinux03
```

4）配置密钥认证（aminglinux01上执行）

```
# 生成密钥对
ssh-keygen

# 将公钥分发到三台机器上
ssh-copy-id aminglinux01
ssh-copy-id aminglinux02
ssh-copy-id aminglinux03

```

5）关闭selinux和firewalld（三台上执行）

```
# 关闭selinux
setenforece 0 #最好是永久关闭，修改/etc/selinux/config配置文件

# 测试环境可以直接关闭firewalld
systemctl stop firewalld

# 如果是生产环境，建议将相关服务加入白名单
firewall-cmd --zone=public --add-service=ceph-mon --permanent
firewall-cmd --zone=public --add-service=ceph --permanent
firewall-cmd --reload
```

6）部署ceph集群（aminglinux01上执行）

```
# 创建工作目录
mkdir my-cluster
cd my-cluster

# create 集群
ceph-deploy new aminglinux01 aminglinux02 aminglinux03 #此时将在当前目录里生成配置文件ceph.conf和monitor secret keyring (ceph.mon.keyring)

# 安装ceph包
ceph-deploy install aminglinux01 aminglinux02 aminglinux03

# 初始化ceph-mon, 只有aminglinux01为mon节点
ceph-deploy mon create-initial  #执行完这步后，会生成很多.keyring的文件

# 分发配置文件和密钥
ceph-deploy admin aminglinux01 aminglinux02 aminglinux03

# 安装ceph-mgr
ceph-deploy mgr create aminglinux01

# 增加osd
ceph-deploy osd create --data /dev/sdb aminglinux01
ceph-deploy osd create --data /dev/sdb aminglinux02
ceph-deploy osd create --data /dev/sdb aminglinux03

# 查看集群状态
ceph -s 
```

目前ceph集群的状态是这样的：

![](https://github.com/aminglinux/linux2019/blob/master/images/ceph1.png?raw=true)


7）扩展集群

```
# 增加元数据服务器(如果想要使用ceph的文件系统存储CephFS，就必须要有元数据服务器即mds)
ceph-deploy mds create aminglinux01

# 增加ceph-mon，前面只有一个aminglinux01节点为mon
ceph-deploy mon add aminglinux02 aminglinux03

# 增加ceph-mon之后，ceph会同步选举信息在所有节点，可以用如下命令查看quorum（选举状态）
ceph quorum_status --format json-pretty

# 增加额外的manager，防止一个出现故障时，还可以使用其他的
ceph-deploy mgr create aminglinux02 aminglinux03 

# 增加rgw实例（如果你想使用ceph的对象存储服务，这一步是必须要做的）
# rgw会监听7480端口
ceph-deploy rgw create aminglinux01

```

如果以上扩展部分都执行了，那么目前为止各节点以及角色如下：

主机名 | IP |角色
-------|---------|----
aminglinux01|192.168.222.128|部署节点、mon节点、osd节点、mds、mgr、rgw
aminglinux02|192.168.222.129|mon节点、osd节点、mgr
aminglinux03|192.168.222.130|mon节点、osd节点、mgr


### ceph块设备支持

前面我们已经了解到，存储类型大体上分为三种：块、对象、文件系统，其实ceph对于这三种都是支持的，下面看如何搭建ceph的块存储。

1）准备一台机器（aminglinux04），作为ceph的客户端节点，配置hosts和密钥认证
```
ssh-copy-id aminglinux04
```

2）如果是CentOS7系统，需要对内核做一个升级，因为ceph要求内核版本为4.x，步骤如下：
```
rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
yum -y install https://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
yum --enablerepo=elrepo-kernel install kernel-lt
grub2-set-default 0
grub2-mkconfig -o /boot/grub2/grub.cfg
reboot
```

3）安装ceph-client到aminglinux04节点上（aminglinux01上执行）
```
ceph-deploy install aminglinux04 
ceph-deploy admin aminglinux04 #拷贝配置文件到aminglinux04
```

4）创建块设备pool（以下在aminglinux01上执行）
```
rbd pool init aming #这里的aming为块设备存储池名字
```

5）配置块设备（以下在aminglinux04上执行）
```
rbd create ceph_disk1 --size 4096  # 块设备名字叫ceph_disk1, 大小为4096MB
rbd list #查看所有的块设备
rbd map cephe_disk1 --name client.admin #映射镜像到块设备，输出结果为/dev/rbd0，这个就是我们刚刚创建的块设备
rbd showmapped #查看map信息
mkfs.ext4 /dev/rbd/aming/ceph_disk1  #格式化块设备，当然也可以直接操作/dev/rbd0，它们是一样的
mmount /dev/rbd0  /data #挂载
```

6）ceph块设备常用的操作
```
# 在指定pool里面创建块设备
rbd create {block name} --size 4096 -p {pool-name}
如：rbd create c_disk2 --size 1024 -p aming

# 查询块设备镜像
rbd ls

# 查询块设备镜像信息
rbd info aming/ceph_disk1 #指定aming存储池

# 增加镜像空间
rbd resize --size 2048 c_disk2

# 减少镜像空间
rbd resize --size 1024 c_disk2 --allow-shrink

# 删除块设备
rbd rm c_disk2
rbd rm aming/c_disk2 #指定aming存储池

```

### ceph文件系统（CephFS）

我们使用第四台机器aminglinux04作为客户端。需要在部署节点修改hosts，并配置密钥认证。

和块设备一样，也需要4.x版本的内核支持。所以，需要对aminglinux04升级Linux内核到4.x


1）在部署节点执行

cphe-deploy install aminglinux04

2） 创建FS
ceph osd pool create cephfs_data 128 
ceph osd pool create cephefs_metadata 128
ceph fs new fs_01 cephfs_metadata cephfs_data

3）创建客户端密钥文件
cat /etc/ceph/ceph.client.admin.keyring #在aminglinux04上执行，将key = 后面的那一串字符写入到admin.secret文件里,你也可以直接执行下面的命令
grep -A1 'client.admin' /etc/ceph/ceph.client.admin.keyring |tail -1 |awk -F 'key = ' '{print $2}' > /etc/ceph/admin.secret 

4）挂载FS
mkdir /mnt/cephfs
mount -t ceph aminglinux01:6789:/ /mnt/cephfs -o name=admin,secretfile=/etc/ceph/admin.secret

5）也可以用FUSE挂载FS
ceph-fuse -k /etc/ceph/ceph.client.admin.keyring  -m aminglinux01:6789:/ /mnt/cephfs


参考文档  https://www.guai.im/2016/07/21/ceph-deploy-setup/



